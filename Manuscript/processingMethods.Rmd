
## ANTs cortical thickness


_Cross-sectional processing_

A thorough discussion of the ANTs cross-sectional thickness estimation framework
was previously discussed in [@Tustison:2014ab].  As a brief review, given a T1-weighted brain MR image,
processing comprises the following  major steps (cf Figure 1 of [@Tustison:2014ab]):

1. N4 bias correction [@Tustison:2010ac],
2. brain extraction [@avants2010a],
3. Atropos $n$-tissue segmentation [@Avants:2011aa], and
4. cortical thickness estimation [@das2009].

ROI-based quantification is achieved \textcolor{red}{through joint label fusion} [@Wang:2013ab] \textcolor{red}{of
the cortex coupled with the MindBoggle-101 data.  These data use the Desikan–Killiany–Tourville (DKT)
labeling protocol} [@Klein:2012aa] \textcolor{red}{to parcellate each cortical hemisphere into 31 anatomical regions}
(cf Table \ref{table:dkt_labels}).
This pipeline has since been enhanced by the implementation [@Tustison:2016aa] of a patch-based
denoising algorithm [@Manjon:2010aa] as an optional preprocessing step and multi-modal
integration capabilities (e.g., joint T1- and T2-weighted image processing).  

\input{dktRegions.tex}

For evaluation, voxelwise regional thickness statistics were summarized based on the DKT
parcellation scheme.  Test-retest error measurements were presented
from a 20 cohort subset of both the OASIS [@oasis] and MMRR [@landman2011] data sets
and compared with the
corresponding FreeSurfer thickness values.    Further evaluation employed a training/prediction
paradigm whereby DKT regional cortical thickness values generated from 1205
images taken from four publicly available data sets (i.e., IXI [@ixi], MMRR,
NKI [@nki], and OASIS) were used to predict age and gender using linear and
random forest [@breiman2001] models.
The resulting regional statistics (including cortical thickness, surface area [@Lehmann:2012aa],
volumes, and Jacobian determinant values) were made available online [@kapowski].  These include the
corresponding FreeSurfer measurements which are also publicly available for research
inquiries (e.g., [@Hasan:2016aa]).
Since publication, this framework has been used in a number of studies
(e.g., [@Price:2015aa;@Wisse:2015aa;@Betancourt:2015aa]).


_Unbiased longitudinal processing_

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../Figures/longitudinalPipeline.png}
\caption{Diagrammatic illustration of the ANTs longitudinal cortical thickness pipeline
for a single subject with $N$ time points.  From the $N$ original T1-weighted
images (left column, yellow panel) and the group template and priors (bottom row,
green panel), the single-single subject template (SST) and auxiliary prior images
are created (center, blue panel).  These subject-specific template and other
auxiliary images are used to generate the individual time-point cortical
thickness maps, in the individual time point's native space (denoted as
``Longitudinal-native'' in the text).  Optionally, one can
rigidly transform the time-point images prior to segmentation and cortical thickness
estimation (right column, red panel).  This alternative processing scheme is referred
to as ``Longitudinal-SST''.  For regional thickness values, regional labels
are propagated to each image using a given atlas set \textcolor{red}{(with cortical labels)
and joint label fusion.}}
\label{fig:pipeline}
\end{figure}

Given certain practical limitations (e.g., subject recruitment and retainment),
as mentioned earlier, many researchers employ cross-sectional acquisition and
processing strategies for studying developmental phenomena.  Longitudinal
studies, on the other hand, can significantly reduce inter-subject measurement variability.
The ANTs longitudinal cortical thickness pipeline extends the ANTs cortical
thickness pipeline for longitudinal studies which takes into account various
bias issues previously discussed in the literature
[@Yushkevich:2010aa;@Reuter:2011aa;@Reuter:2012aa].

Given $N$ time-point T1-weighted MR images (and, possibly, other modalities)
and representative images to create a population-specific template and
related images, the longitudinal pipeline consists of the following steps:

1. (Offline):  Creation of the group template and corresponding prior probability images.
1. Creation of the unbiased single-subject template (SST).
2. Application of the ANTs cross-sectional pipeline to the SST.  This processes the SST based on the group template.
3. Creation of the SST prior probability maps.
4. (Optional):  Rigid transformation of each individual time point to the SST.
5. Application of the ANTs cross-sectional pipeline -- with SST as reference template -- to each individual time-point image.  This processes individual time points based on the SST yet also allows concatenation of transforms to the group template.
6. Joint label fusion to determine the cortical ROIs for analysis.

An overview of these steps is provided in Figure \ref{fig:pipeline} which we describe
in greater detail below.  

<!--
One of the most significant findings presented below
is that the common step of transforming each individual
time point to the SST is suboptimal in that the corresponding interpolation
effects decrease the quality of cortical thickness measurements over
processing in native space.  
-->

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../Figures/adniTemplate2.png}
\caption{Top row:  Canonical views of the template created from 52 cognitively normal subjects
of the ADNI-1 database.  The prior probability mask for the whole brain (middle row)
and the six tissue priors (bottom row) are used to ``seed'' each single-subject template for creation of
a probabilistic brain mask and probabilistic tissues priors during longitudinal
processing.}
\label{fig:template}
\end{figure}

__ADNI group template, brain mask, and tissue priors.__  Prior to any individual subject processing, the group
template is constructed from representative population data [@Avants:2010aa].  For the ADNI-1 processing
described in this work, we created a population-specific template from 52 cognitively normal ADNI-1
subjects.  Corresponding brain and tissue prior probability maps for the CSF, gray matter,
white matter,  deep gray matter, brain stem, and cerebellum were created as described
in [@Tustison:2014ab].  A brief overview of this process is also provided in the  section
concerning creation of the single-subject template.
Canonical views of the ADNI-1 template and corresponding auxiliary images are given
in Figure \ref{fig:template}.



__Single-subject template, brain mask, and tissue priors.__
With the ADNI-1 group template and prior probability images,
each subject undergoes identical processing.  First, an average shape and intensity single
subject template (SST) is created from all time-point images  using the
same protocol [@Avants:2010aa] used to produce the ADNI-1 group template.
Next, six probabilistic tissue maps (cerebrospinal
fluid (CSF), gray matter (GM), white matter (WM), deep gray matter (striatum + thalamus),
brain stem, and cerebellum) are generated in the space of the SST.  This requires processing
the SST through two parallel workflows.  First,
the SST proceeds through the standard cross-sectional ANTs cortical thickness pipeline which generates
a brain extraction mask and the CSF tissue probability map, $P_{Seg}(CSF)$.  Second, using
a data set of 20 atlases from the OASIS data set that have been expertly annotated
\textcolor{red}{and made publicly available}
[@Klein:2012aa], a multi-atlas joint label fusion step (JLF) [@Wang:2013ab] is performed
to create individualized probability
maps for all six tissue types.  Five of the JLF probabilistic tissue
estimates (GM, WM, deep GM, brain stem, and cerebellum) and the JLF CSF estimate,
$P_{JLF}(CSF)$,
are used as the SST prior probabilities after smoothing with a Gaussian kernel
(isotropic, $\sigma = 1 mm$) whereas the CSF SST tissue probability
is derived as a combination of the JLF and segmentation CSF estimates, i.e.,
$P(CSF) = \max\left( P_{Seg}(CSF), P_{JLF}(CSF) \right)$, also smoothed
with the same Gaussian kernel.  Finally, $P(CSF)$ is subtracted out from the other
five tissue probability maps.  The final version of the SST and auxiliary images enable
unbiased mappings to the group template, subject-specific tissue segmentations, region of interest volumes and
cortical thickness maps for each time point of the original longitudinal image series.

__Individual time point processing.__ The first step for subject-wise
processing involves creating the SST
from all the time points for that individual [@Avants:2010aa].  For the cross-sectional ANTs processing,
the group template and auxiliary images are used to perform tasks such as individual
brain extraction and $n$-tissue segmentation prior to cortical thickness estimation [@Tustison:2014ab].
However, in the longitudinal variant, the SST serves this purpose.  We thus map the SST and its priors to the native space of each time point where individual-level segmentation and cortical thickness is
estimated.  Note that this unbiased longitudinal pipeline is completely agnostic concerning ordering of
the input time-point images, i.e., we "treat all time points exactly the same."

During the initial development of this work, it was thought that an option allowing
for rotation of the
individual time points to the SST would be of benefit, similar to FreeSurfer, in reducing variability,
minimizing or eliminating possible orientation bias, and \textcolor{red}{possibly} permitting a 4-D
segmentation given that the underlying Atropos segmentation implementation is dimensionality-agnostic
[@Avants:2011aa].  Regarding the 4-D brain segmentation, any possible benefit is potentially
outweighed by the occurrence of "over-regularization" [@Reuter:2012aa] whereby
smoothing across time reduces detection ability of large time-point changes.
Additionally, it is less than straightforward to accommodate irregular temporal sampling
such as the acquisition schedule of the ADNI-1 protocol.  

In the FreeSurfer longitudinal stream, each time-point image is processed using
the FreeSurfer cross-sectional stream.  The resulting processed data from all time points
is then used to create a mean, or median, single-subject template.  Following
template creation, each time-point image is rigidly transformed to the template space where
it undergoes further processing (e.g., white and pial surface deformation).  This
reorientation to the template space "further reduce[s] variability" and permits an
"implicit vertex correspondence" across all time points [@Reuter:2012aa].
The ANTs longitudinal workflow shares some common aspects of its FreeSurfer
analog but differs in others as outlined above.  


<!--

However, during the course of this work we discovered that reorienting each time point image to the SST has
significant detrimental measurement effects in which interpolation bias induces
artificial anatomical changes and these changes correlate significantly with specific
regions.  Since we are measuring the thickness of the highly convoluted cortex
involving measurements on the order of $2-8 mm$ from images with $\sim 1 mm^3$
voxels, these artificial changes significantly effect clinically related
criteria of measurement quality such as confidence intervals and predictability.
This is discussed further in the following sections.

-->

__Joint label fusion and pseudo-geodesic for large cohort labeling.__  Cortical
thickness ROI-based analyses are performed using joint label fusion [@Wang:2013ab]
and whatever cortical parcellation scheme is deemed appropriate for the specific
study.  The brute force application of the joint label fusion algorithm would
require $N$ pairwise registrations for each time-point image where $N$ is the
number of atlases used.  This would require a significant computational cost for
a relatively large study such as ADNI.  Instead, we use the "pseudo-geodesic" approach
for mapping atlases to individual time point images (e.g., [@Tustison:2015aa]).  The transformations between
the atlas and the group template are computed offline.  With that set of transforms,
we are able to concatenate a set of existing transforms from each atlas through
the group template, to the SST, and finally to each individual time point \textcolor{red}{for
estimating regional labels for each image.}
