
# Methods and materials

## Longitudinal ADNI imaging data

![Demographic breakdown of the number of ADNI subjects by diagnosis (i.e., normal,
mild cognitive impairment (MCI), late mild cognitive impairment (LMCI),
and Alzheimer's disease (AD)).  Within each panel we plot the number of subjects
(by gender) per visit---baseline ("bl") and $n$ months ("m$n$").](../Figures/demoPlot.png)


[@Jack:2008aa]


## ANTs Cortical thickness estimation

### Cross-sectional processing

A thorough discussion of the ANTs cross-sectional thickness estimation framework
was previously discussed in [@Tustison:2014ab].  Briefly, given a T1-weighted brain MR image,
processing comprises the following five major steps (cf Figure 1 of [@Tustison:2014ab]):

* N4 bias correction [@Tustison:2010ac],
* brain extraction [@avants2010a],
* Atropos six-tissue segmentation [@Avants:2011aa], and
* cortical thickness estimation [@das2009].

ROI-based quantification is achieved through the use of the joint label fusion
approach of [@Wang:2013ab] and the use of the MindBoggle-101 data labeled using
the Desikan–Killiany–Tourville (DKT) protocol [@Klein:2012aa] consisting of 31
labels per hemisphere (cf Table 1).
This pipeline has since been enhanced by the implementation [@Tustison:2016aa] of a patch-based
denoising algorithm [@Manjon:2010aa] as an optional preprocessing step and multi-modal
integration capabilities.  

\input{dktRegions.tex}

For evaluation, regional thickness statistics were calculated based on the DKT
parcellation scheme.  Test-retest error measurements were presented
from a cohort of 20 atlases taken from the OASIS data set which had been manually
labeled [@Klein:2012aa] and compared with the
analogous FreeSurfer thickness values.    Further evaluation employed a training/prediction
paradigm whereby DKT regional cortical thickness values generated from 1205
images taken from four publicly available data sets (i.e., IXI [@ixi], MMRR [@landman2011],
NKI [@nki], and OASIS [@oasis]) were used to predict age and gender using linear and
random forest models.  Although repeatability was comparable between the two packages,
predictive accuracy was improved with ANTs versus FreeSurfer.

The resulting regional statistics (including cortical thickness, surface area [@Lehmann:2012aa],
volumes, and Jacobian determinant values) are available online.[^2]  These include the corresponding
FreeSurfer measurements which are also publicly available for research
studies (e.g., [@Hasan:2016aa]).
Since publication this pipeline has been used in a number of cross-sectional studies
(e.g., [@Price:2015aa;@Wisse:2015aa;@Betancourt:2015aa]).

[^2]: https://github.com/ntustison/KapowskiChronicles


<!--
A further extension is the potential inclusion of additional modalities
(e.g. T2-weighted).  
-->

### Unbiased longitudinal processing

![Diagrammatic illustration of the ANTs longitudinal cortical thickness pipeline
for a single subject with $N$ time points.  From the $N$ original T1-weighted
images (left column, yellow panel) and the group template and priors (bottom row,
green panel), the single-single subject template (SST) and auxiliary prior images
are created (center, blue panel).  These subject-specific template and other
auxiliary images are used to
generate the individual time-point cortical thickness maps.  Optionally, one can
rigidly transform the time-point images prior to segmentation and cortical thickness
estimation (right column, red panel).  For regional thickness values, regional labels
can be propagated to each image using a given atlas set and cortical parcellation scheme.](../Figures/longitudinalPipeline.png)

Given certain practical limitations (e.g., subject recruitment and retainment),
as mentioned earlier, many researchers employ cross-sectional acquisition and
processing strategies for studying developmental phenomena.  Longitudinal
studies can significantly reduce inter-subject measurement variability.
The ANTs longitudinal cortical thickness pipeline extends the ANTs cortical
thickness pipeline for longitudinal studies which takes into account various
bias issues previously discussed in the literature
[@Yushkevich:2010aa;@Reuter:2011aa;@Reuter:2012aa].
Given $N$ time-point T1-weighted MR images and a group template and prior
probability maps (described below), the longitudinal pipeline consists of the following steps:

1. Create single-subject template (SST) and prior probability maps.
2. (Optional):  Transform each individual time point to the SST.
3. Apply the ANTs cross-sectional pipeline to each individual time-point using
SST-based priors.

An overview of these steps is provided in Figure 1 which we describe
in greater detail below.  One of the most significant findings presented below
is that the common step of transforming each individual
time point to the SST is suboptimal in that the corresponding interpolation
effects decrease the quality of cortical thickness measurements over
segmentation and cortical thickness estimation in native space.  

__ADNI normal group template.__  Prior to any subject processing, the group
template is generated from the population data [@Avants:2010aa] or one can use one of our publicly
available templates [@Tustison:2014ab].  For ADNI processing we created an
ADNI-specific template from 52 normal subjects.  We employed our brain extraction
method described in [@avants2010a] to create a corresponding probabilistic brain
extraction map.  We also generated six tissue prior probability
maps for the CSF, gray matter, white matter, deep gray matter, brain stem, and
cerebellum.  

![Top row:  Canonical views of the template created from 52 normal subjects
of the ADNI database.  The prior probability mask for the whole brain (middle row)
and the 6 tissue priors (bottom row) are used to "seed" each SST during longitudinal
processing.](../Figures/adniTemplate2.png)

__Single-subject template, brain mask, and tissue priors.__ The SST is then
segmented via the processing protocol
reported in [@Tustison:2014aa] using the group template and tissue priors.
This results in a probabilistic estimate of the CSF and the brain mask.  Joint
label fusion (JLF) of a set of atlases with six labels (CSF, gray
matter, white matter, deep gray matter, brain stem, and cerebellum) is used to get a
probabilistic estimate of the six tissues.



<!--
The latter five JLF probabilistic tissue
estimates are used as the SST prior probabilities whereas the CSF SST prior probability
is derived as a combination of the JLF and segmentation CSF estimates.


, i.e.,
$P(CSF) = \max\left( P_{Seg}(CSF), P_{JLF}(CSF) \right)$.  

The T1-weighted image at each
time point is rigidly aligned to the template and processed through original cortical
thickness pipeline using the SST template and auxiliary images
(brain extraction mask and tissue priors).  Cortical labelings obtained using JLF are
then used to quantify ROI-based statistics.
-->

Following the offline construction of the group template and prior probability images,
each subject undergoes similar processing.  First, an average shape and intensity single
subject template (SST) is created from all time point images [@Avants:2010aa].  Each
time point image is then rigidly aligned to the SST.  The SST prior probability maps are
created using a protocol combining brain extraction and a six-tissue segmentation and
a six-label joint label fusion processing of the SST.  After the SST template priors are
created, each time point image is rigidly aligned to the template to reduce the
effect of coordinate system or interpolation bias.

Each rigidly-aligned time point image is processed using the ANTs original pipeline
and the SST template and template priors resulting in a brain extraction mask, six-tissue
segmentation, and a cortical thickness map for each time point image.  The cortical ROIs
from the DKT atlases are propogated to each time point using a "pseudo-geodesic" mapping
and joint label fusion.


Subsequent processing segments
the SST into six probabilistic tissues classes:   cerebrospinal
fluid (CSF), gray matter (GM), white matter (WM), deep gray matter (striatum + thalamus),
brain stem, and cerebellum.  This requires processing the SST through two parallel workflows.  First,
the SST proceeds through the standard ANTs cortical thickness pipeline which generates
a brain extraction mask and the CSF posterior probability map.  Second, using
a data set of expert annotations [@Klein:2012aa], a class-leading multi-atlas joint label fusion step [@Wang:2013ab] is performed to
create individualized probability maps for all tissue types.  This final version of the SST enables
unbiased mappings to the group template, subject-specific tissue segmentations, region of interest volumes and
cortical thickness maps for each of the original time series images.
The corresponding cortical labelings (generated
using a multi-atlas label fusion approach and a selected cortical parcellation protocol)
are then used to tabulate regional thickness and area values for statistical analysis.
Other modalities are then mapped to the group template through these unbiased
transformations, as in [@Tustison:2014aa;@Avants:2015aa]


_"Cooking" the template priors._

_Pseudo-geodesic for large cohort labeling._
