
## Statistical evaluation

\textcolor{black}{Based on the above ANTs pipeline descriptions, there are three
major variants for cortical thickness processing of longitudinal data.} We
denote these alternatives as:

* __ANTs Cross-sectional__ (or __ANTs Cross__). Process each subject's time point independently using the
  cross-sectional pipeline originally described in [@Tustison:2014ab].
* __ANTs Longitudinal-SST__ (or __ANTs SST__).  Rigidly transform each subject to the SST and then
   segment and estimate cortical thickness in the space of the SST.
* __ANTs Longitudinal-native__ (or __ANTs Native__).  Segment and estimate cortical thickness in the native space.

\textcolor{black}{For completeness, we also include a comparison with both the cross-section and
longitudinal FreeSurfer v5.3 streams respectively denoted as ``FreeSurfer Cross-sectional'' (or
``FS Cross'') and ``FreeSurfer Longitudinal'' (or ``FS Long'').}

\textcolor{black}{Possible evaluation strategies could employ manual measurements in
the histological} [@rosas2002] \textcolor{black}{or virtual} [@kuperberg2003]
\textcolor{black}{domains but would require an inordinate labor effort for collection
to be comparable with the size of data sets currently analyzed.  Other quantitative measures
representing ``reliability'', ``reproducibility'', or, more generally, ``precision''
can also be used to characterize such tools.  For example,} [@jovicich2013]
\textcolor{black}{used FreeSurfer cortical thickness measurements across image
acquisition sessions to demonstrate improved reproducibility with the longitudinal
stream over the cross-sectional stream.  In} [@Klein:2017aa] \textcolor{black}{
comparisons for ANTs, FreeSurfer, and the proposed method were made using
the range of measurements and their correspondence to values published in the
literature.  However, none of these precision-type measurements, per se,
indicate the utility of a pipeline-specific cortical thickness value as a potential biomarker.  
For example, Figure 8} in [@Tustison:2014ab] \textcolor{black}{confirms what was found in} [@Klein:2017aa]
\textcolor{black}{which is that the range of ANTs cortical thickness values for a particular region
exceeds those of FreeSurfer.  However, for the same data, the demographic predictive
capabilities of the former was superior to that of the latter.  Thus, better
assessment strategies are necessary for determining clinical utility.  For example,
the intra-class correlation (ICC) coefficient used
in} [@Tustison:2014ab] \textcolor{black}{demonstrated similarity in both ANTs and FreeSurfer
for repeated acquisitions despite the variance discrepancy between both sets of measurements.  
This is understood with the realization that the ICC takes into account both inter-observer
and intra-observer variability.}

### Regional within-subject and between-subject variance

\textcolor{black}{A summary measure related to the ICC statistic} [@verbeke2009linear]
\textcolor{black}{is used to quantify the relative performance of these
cross-sectional and longitudinal ANTs pipeline variants and a comparison
with their FreeSurfer comparisons.  Specifically, we use longitudinal
mixed-effects (LME) modeling to quantify pipeline-specific between-subject
and within-subject variabilities with the intuition that comparative
performance is determined by maximizing the ratio between the former
and the latter.}  Such a quantity implies greater within-subject reproducibility
while distinguishing between patient sub-populations
\textcolor{black}{(e.g., Alzheimer's disease diagnosis)}. As such this will
amount to higher precision when cortical thickness is used as a predictor
variable or model covariate in statistical analyses upstream. This criterion is
immediately estimable from the LME model \eqref{eq::lme1} outlined below.

LME models comprise a well-established and widely used class of regression models
designed to estimate cross-sectional and longitudinal linear associations between
quantities while accounting for subject specific trends.  As such, these models
are useful for the analysis of longitudinally collected cohort data.
Indeed, [@Bernal-Rusiel:2013aa] provide an introduction to the mixed-effects methodology
in the context of longitudinal neuroimaging data and compare it empirically to
competing methods such as repeated measures ANOVA. For more complete treatments of
the subject matter, see [@verbeke2009linear] and [@fitzmaurice2012applied].
LME models are also useful for estimating and comparing within-subject and
between-subject variability after conditioning out systematic time trends in
longitudinally measured data.  In the context of the current investigation, by
fitting simple LME models to the data resulting from cross-sectional and longitudinal
processing techniques, we are able to quantify the relative performance of each approach
with respect to within-subject, between-subject, and total variability in a way that
[@reuter2012] hint at in their exposition of the longitudinal FreeSurfer stream.

As previously noted we observed a longitudinal sampling of cortical thickness measurements
from 62 separate regions of interest.  To assess the above variability-based criteria
while accounting for changes that may occur through the passage of time, we used a
Bayesian LME model for parameter estimation.  Let $Y^k_{ij}$ denote the $i^{th}$
individual's cortical thickness measurement corresponding to the $k^{th}$ region of
interest at the time point indexed by $j$.  Under the Bayesian paradigm we utilized a model of the form
\begin{gather}
\label{eq::lme1}
Y^k_{ij} \sim N(\alpha^k_i + \beta^k t,
\sigma_k^2) \\ \nonumber \alpha^k_i \sim N(\alpha^k_0, \tau^2_k) \qquad
\alpha^k_0, \beta^k \sim N(0,10)  \qquad \sigma_k,  \tau_k \sim
\mbox{Cauchy}^+ (0, 5)
\end{gather}
Specification of variance priors to half-Cauchy distributions reflects commonly accepted
practice in the context of hierarchical models [@gelman2006prior]. In this model,
$\tau_k$ represents the between-subject standard deviation, and $\sigma_k$ represents
the within-subject standard deviation, conditional upon time.  For each region $k$,
the quantity of interest is thus the ratio
\begin{equation}\label{eq::var_rat}
r^k = \frac{\tau_k}{\sigma_k}, \ k = 1, \dots, 62 \, .
\end{equation}
This ratio is at the heart of classical statistical discrimination methods as it
features both in the ANOVA methodology and in Fisher's linear discriminant analysis.
These connections are important since the utility of cortical thickness as a biomarker
lies in the ability to discriminate between patient sub-populations with respect to
clinical outcomes.  The posterior distribution of $r^k$ was summarized via the posterior
median where the posterior distributions were obtained using the Stan probabilistic
programming language [@carpenter2016stan].

<!--
For each processing method, we performed 62 independent, region-specific regressions.  In order to compare results between methods, we considered the quantities
\begin{equation}
\delta^k = r^k_l - r^k_c\ , \quad \mbox{and} \quad \delta^k_{norm} = \frac{r^k_l - r^k_c}{r^k_l + r^k_c} \ ,
\end{equation}
denoting the variance ratio for the longitudinal method minus that of the cross-sectional method and the normed difference between ratios, respectively. Since a large $r^k$ implies a higher between-subject to within-subject variability ratio, a positive estimate of $\delta^k$ that is large in magnitude implies that the longitudinal processing method is preferable to the cross-sectional method.  Conversely, a negative estimate that is large in magnitude implies that the cross-sectional processing method is preferable to the longitudinal method.
-->

### Practical implications of the variance ratio, a case study

The entorhinal cortex (EC) is one of the earliest regions to exhibit tau pathology
in the Alzheimerâ€™s brain and is one of the first regions to show signs of
neurodegenerative change [@Hyman:1984aa;@Braak:1991aa;@Van-Hoesen:1991aa;@Yassa:2014aa].
In the ADNI sample, EC cortical thickness was the most powerful measure of
structural change both in MCI and AD subjects [@Holland:2009aa]. EC thinning
was also found to precede and predict hippocampal atrophy [@Desikan:2010aa]
and to predict conversion to AD with the greatest accuracy [@Ewers:2012aa].
Thus, we chose the EC to be the target of an additional focused analysis to determine
the relative utility of the different ANTs pipelines for measuring thickness in this
particular region.  Our choice of EC for comparative performance assessment is
motivated both by its selective vulnerability to neurodegenerative processes
as well as the difficulty of image segmentation in that particular region.

As a further assessment of utility as a biomarker, we used LME models and cortical
thickness measurements of the EC to demonstrate how these variability criteria
relate to potential scientific analyses. First, we used model \eqref{eq::lme1}
to show that a greater ratio of between-subject to within-subject variability
results in tighter confidence and credible intervals on the slope parameter $\beta$.
This result indicates more confidence with respect to mean trends over time that are of
common interest when comparing sub-populations of patients. Second, we showed that
smaller within-subject variability corresponds to smaller prediction intervals when
predicting a subject's cortical thickness levels at future visits. This is important
when considering regional cortical thickness measures as candidate biomarkers.  
Third, we use a simple linear regression model to compare the relationship between
total variance and uncertainty with respect to cross-sectional effects.  To do so,
we regress baseline cortical thickness in the entorhinal cortex (EC) over baseline
AD diagnostic status:
\begin{equation} \label{eq::slr}
ECCT_i = \beta_0 + \beta_1 AD_i + \epsilon_i \ .
\end{equation}
In general, lower total variability corresponds to tighter confidence/credible intervals
for cross-sectional covariate effects, and hence higher certainty when evaluating linear
associations between quantities such as cortical thickness and AD status.  If
total variability is similar across processing methods, we would expect to see
credible intervals of roughly the same size.

<!--
_Diagnostic prediction via extreme gradient boosting_

As mentioned earlier, an important component of our previously reported cross-sectional comparative
evaluation [@Tustison:2014ab] incorporated a statistical modeling approach for predicting basic
subject demographics (i.e., age and gender) from the summary DKT regional cortical thickness values.
We used a similar evaluation strategy in this work with the ADNI-1 data.  We built
statistical models from cortical thickness values for predicting the ADNI-specified diagnosis.
However, instead of using the regional cortical thickness values for all time points directly,
we used the longitudinal cortical thickness values for each DKT region of each subject to compute
a subject-specific, region-specific rate-of-thickness-change measurement generated from simple
linear regression of the available data.
Thus, for each subject, we calculated a single set of 62 slope coefficients,
$\mathbf{\zeta} = \{\zeta_1,\zeta_2,\dots,\zeta_{62}\}$,
and a single diagnosis of cognitively normal, MCI, LMCI, or AD.  Note that
the diagnosis for each subject did not change over the course of
the image acquisition schedule permitting this particular evaluative strategy.
This classification scenario yields the following model:
\begin{equation} \label{eq::xgboost_model}
DIAGNOSIS \sim \sum_{k=1}^{62} \zeta_k
\end{equation}  
The motivating idea is that regional thinning is accelerated in some regions versus
others which should be reflected in the assigned diagnostic category [@Holland:2009aa;@Desikan:2010aa].

For model construction, we used extreme gradient boosting, which is a well-performing,
out-of-the-box classifier implemented in the XGBoost [@xgboost]
package for the R project.  Although there are many options available for classification, we chose
this particular technique due to our recent interest in other projects
based on its various successes in other fields.[^1002]  An additional advantage is that XGBoost provides
the "gain" quantity which describes "the improvement in accuracy brought by a feature to the branches
[of the tree or iteration] it is on [@xgboost]." These can be reviewed for
clinical plausibility of the results.


[^1002]: http://stat-computing.org/awards/jmc/winners.html

-->
